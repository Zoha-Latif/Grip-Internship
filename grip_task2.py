# -*- coding: utf-8 -*-
"""Grip task2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g0mg-Ix8s23haKaMIqDzYB8We7otA0v9
"""

#Iris dataset
#Step
#1.Import dataset
#2.apply elbow and Silhouette Score to obtain optimum no of cluster in dataset .it find out value of 3
#3.apply k-mean clustering algorithm and present visually all four feature of irsi dataset.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score

# Load the Iris dataset
iris = load_iris()
X = iris.data
y = iris.target

# Standardize the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Determine the optimum number of clusters using the Elbow method and Silhouette Score
inertia = []
silhouette_scores = []
k_range = range(2, 11)  # Silhouette Score requires at least 2 clusters

for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    inertia.append(kmeans.inertia_)

    # Calculate silhouette score for each k
    score = silhouette_score(X_scaled, kmeans.labels_)
    silhouette_scores.append(score)

# Plot the Elbow method results
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(k_range, inertia, 'bo-', markersize=8)
plt.xlabel('Number of clusters (k)')
plt.ylabel('Inertia')
plt.title('Elbow Method for Optimal k')

# Plot the Silhouette Score results
plt.subplot(1, 2, 2)
plt.plot(k_range, silhouette_scores, 'go-', markersize=8)
plt.xlabel('Number of clusters (k)')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Score for Optimal k')

plt.tight_layout()
plt.show()

# Choose the optimal number of clusters (k) based on the above methods
# For this example, we might choose k=3 based on the Elbow and Silhouette methods

# Apply K-Means with the chosen number of clusters (k=3)
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(X_scaled)
labels = kmeans.labels_

# Visualize the clusters using PCA for dimensionality reduction
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

plt.figure(figsize=(8, 5))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis', marker='o', s=50)
centroids = pca.transform(kmeans.cluster_centers_)
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='X', s=200, label='Centroids')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.title('K-Means Clustering of Iris Dataset')
plt.legend()
plt.show()